{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3751ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "from keras.layers import Input,Conv2D,LSTM\n",
    "from keras.layers import Reshape\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from os import getcwd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "\n",
    "#import keras_tuner\n",
    "import tensorflow as tf\n",
    "\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d24b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a48fe",
   "metadata": {},
   "source": [
    "Tue Aug 17 19:11:03 2021       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
    "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|  No running processes found                                                 |\n",
    "+-----------------------------------------------------------------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "    print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "    print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "    print('re-execute this cell.')\n",
    "else:\n",
    "    print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b654c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f25a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_train(ak,bk,ck):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(191,1)))\n",
    "    for ix in range(0,ak):\n",
    "        model.add(tf.keras.layers.LSTM(units=bk,\n",
    "                            activation = 'tanh',\n",
    "                            recurrent_activation = 'sigmoid',\n",
    "                            return_sequences=True,\n",
    "                           recurrent_dropout = 0))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(units=bk,  activation = 'tanh'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(\n",
    "        learning_rate=ck*2),\n",
    "        loss='mae',\n",
    "        metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca90f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(191,1)))\n",
    "\n",
    "    for i in range(hp.Int('num_layers', 2, 6)):\n",
    "            model.add(\n",
    "                     tf.keras.layers.LSTM(units=hp.Int('units_',\n",
    "                                           128, 2048, 64),\n",
    "                                activation = 'tanh',\n",
    "                                recurrent_activation = 'sigmoid',\n",
    "                                return_sequences=True,\n",
    "                               recurrent_dropout = 0))\n",
    "    model.add(tf.keras.layers.LSTM(units=hp.Int('units_',128, 2048, 64),  activation = 'tanh'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "            optimizer=keras.optimizers.RMSprop(\n",
    "                hp.Choice('learning_rate', [ 1e-3, 1e-4,1e-5,1e-6])),\n",
    "            loss='mae',\n",
    "            metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cfea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, time_steps=1):\n",
    "    Xs = []\n",
    "    for i in range(time_steps,len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "    return np.array(Xs)\n",
    "df=pd.read_csv('/content/drive/MyDrive/ETHUSDT15min.csv')\n",
    "len(df)\n",
    "df['index'] = np.arange(len(df))\n",
    "df['index']=df['index']+1\n",
    "train_size = len(df[:4*24*365+4*24*90*2])\n",
    "test_size = len(df) - train_size\n",
    "\n",
    "train, test = df.price_close.iloc[:train_size], df.price_close.iloc[train_size:len(df)]\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "train=pd.DataFrame(train)\n",
    "test=pd.DataFrame(test)\n",
    "\n",
    "time_steps = 4*24*2\n",
    "\n",
    "X_train= create_dataset(train, time_steps)\n",
    "X_test= create_dataset(test,time_steps)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "y_train = X_train[:,-1]\n",
    "X_train = X_train[:,:-1]\n",
    "\n",
    "y_test = X_test[:,-1]\n",
    "X_test = X_test[:,:-1]\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe7fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from kerastuner import BayesianOptimization\n",
    "\n",
    "tuner_bo = kt.BayesianOptimization(\n",
    "            build_model,\n",
    "            objective='mae',\n",
    "            max_trials=6,\n",
    "            seed=42,\n",
    "            executions_per_trial=1,\n",
    "            overwrite=True\n",
    "        )\n",
    "tuner_bo.search(X_train, y_train,  epochs=1, validation_split=0.2, verbose=1)\n",
    "\n",
    "best_model = tuner_bo.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932095a",
   "metadata": {},
   "source": [
    "Trial 6 Complete [00h 09m 53s]\n",
    "mae: 38.366519927978516\n",
    "\n",
    "Best mae So Far: 30.214330673217773\n",
    "Total elapsed time: 01h 05m 15s\n",
    "INFO:tensorflow:Oracle triggered exit\n",
    "CPU times: user 48min 28s, sys: 1min 10s, total: 49min 38s\n",
    "Wall time: 1h 5min 40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da57effb",
   "metadata": {},
   "source": [
    "Results summary\n",
    "Results in ./untitled_project\n",
    "Showing 10 best trials\n",
    "Objective(name='mae', direction='min')\n",
    "Trial summary\n",
    "Hyperparameters:\n",
    "num_layers: 2\n",
    "units_: 2048\n",
    "learning_rate: 0.001\n",
    "Score: 30.214330673217773\n",
    "Trial summary\n",
    "Hyperparameters:\n",
    "num_layers: 2\n",
    "units_: 576\n",
    "learning_rate: 0.001\n",
    "Score: 35.680477142333984\n",
    "Trial summary\n",
    "Hyperparameters:\n",
    "num_layers: 4\n",
    "units_: 1344\n",
    "learning_rate: 0.001\n",
    "Score: 38.366519927978516\n",
    "Trial summary\n",
    "Hyperparameters:\n",
    "num_layers: 6\n",
    "units_: 2048\n",
    "learning_rate: 0.001\n",
    "Score: 48.298255920410156\n",
    "Trial summary\n",
    "Hyperparameters:\n",
    "num_layers: 3\n",
    "units_: 1856\n",
    "learning_rate: 1e-05\n",
    "Score: 155.6876678466797\n",
    "Trial summary\n",
    "Hyperparameters:\n",
    "num_layers: 5\n",
    "units_: 192\n",
    "learning_rate: 1e-06\n",
    "Score: 220.03173828125\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe01f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = tuner_bo.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values \n",
    "a=hps['num_layers']\n",
    "b=hps['units_']\n",
    "c=hps['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02153957",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=3\n",
    "b=2048\n",
    "c=6.250000073038109e-09/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model1=build_model_train(a,b,c)\n",
    "model1.load_weights('/content/drive/MyDrive/checkpoint2/2period_12-0.58.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb32d3",
   "metadata": {},
   "source": [
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "===============================================================\n",
    "lstm (LSTM)                  (None, 191, 2048)         16793600  \n",
    "_________________________________________________________________\n",
    "lstm_1 (LSTM)                (None, 191, 2048)         33562624  \n",
    "_________________________________________________________________\n",
    "lstm_2 (LSTM)                (None, 191, 2048)         33562624  \n",
    "_________________________________________________________________\n",
    "lstm_3 (LSTM)                (None, 2048)              33562624  \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 1)                 2049      \n",
    "===============================================================\n",
    "Total params: 117,483,521\n",
    "Trainable params: 117,483,521\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4,min_delta=0.0001, mode='min',restore_best_weights=True)\n",
    "n=tf.keras.callbacks.TerminateOnNaN()\n",
    "rp=tf.keras.callbacks.ReduceLROnPlateau(monitor='loss',mode='min', factor=0.3, patience=1, verbose=2, min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "checkpoint_filepath = '/content/drive/MyDrive/checkpoint7/retrain-{epoch:02d}-{loss:.2f}.hdf5'\n",
    "mcc = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.fit(X_train,y_train,\n",
    "            batch_size=320,\n",
    "            verbose=2,\n",
    "            epochs=200,\n",
    "            callbacks=[es,n,rp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb109fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f784da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/checkpoint2/diff_eth_2.csv\") as file_name:\n",
    "    diff = np.loadtxt(file_name, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_eth_train_percent=[]\n",
    "k=0\n",
    "for j in range(0,len(X_train)):\n",
    "    X_train_pred= model1.predict(np.expand_dims(X_train[j],axis=0))\n",
    "    print (k)\n",
    "    k+=1\n",
    "    dif=(X_train_pred-y_train[j])/y_train[j]\n",
    "    diff_eth_train_percent=np.append(diff_eth_train_percent,dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a317d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/content/drive/MyDrive/checkpoint2/diff_eth_train_percent.csv\", diff_eth_train_percent, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class stopAtLossValue(Callback):\n",
    "\n",
    "        def on_batch_end(self, batch, logs={}):\n",
    "            THR = 0.6 #Assign THR with the value at which you want to stop training.\n",
    "            if logs.get('loss') <= THR:\n",
    "                 self.model.stop_training = True\n",
    "sal=stopAtLossValue()\n",
    "\n",
    "es=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4,min_delta=0.0001, mode='min',restore_best_weights=True)\n",
    "n=tf.keras.callbacks.TerminateOnNaN()\n",
    "rp=tf.keras.callbacks.ReduceLROnPlateau(monitor='loss',mode='min', factor=0.3, patience=1, verbose=2, min_delta=0.0001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/checkpoint2/diff_eth_2.csv\") as file_name:\n",
    "    diff = np.loadtxt(file_name, delimiter=\",\")\n",
    "    \n",
    "diff_test_n=diff\n",
    "import statistics\n",
    "from scipy.stats import norm\n",
    "eh=225\n",
    "var_ep=np.linspace(225, 225*2, num=10)\n",
    "\n",
    "mean=stats.describe(diff_test_n)[2]\n",
    "var=stats.describe(diff_test_n)[3]\n",
    "up_level=mean+3*var\n",
    "down_level=mean-3*var\n",
    "\n",
    "\n",
    "y_test_pred_n=[]\n",
    "y_test_real_n=[]\n",
    "an_n=[]\n",
    "an_in=[]\n",
    "p_val=[]\n",
    "k1=[]\n",
    "\n",
    "\n",
    "for i in range (0,int(len(X_test)/191.)):\n",
    "    print (i)\n",
    "\n",
    "    X_test_n=X_test[i*191:(i+1)*191]\n",
    "    y_test_n=y_test[i*191:(i+1)*191]\n",
    "    print (X_test_n.shape)\n",
    "    \n",
    "    for j in range(0,len(X_test_n)):\n",
    "    \n",
    "    \n",
    "    X_test_pred= model1.predict(np.expand_dims(X_test_n[j],axis=0))\n",
    "\n",
    " \n",
    "    d=y_test_n[j]-X_test_pred\n",
    "    diff_test_n=np.append(diff_test_n,d)\n",
    "    mean=stats.describe(diff_test_n)[2]\n",
    "    var=stats.describe(diff_test_n)[3]\n",
    "    up_level=mean+3*var\n",
    "    down_level=mean-3*var\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # compare samples\n",
    "    stat, p = ttest_ind(diff, diff_test_n)\n",
    "\n",
    "    alpha = 0.4\n",
    "\n",
    "    if p > alpha:\n",
    "        \n",
    "        print('Same distributions')\n",
    "        p_val=np.append(p_val,p)\n",
    "\n",
    "        y_test_pred_n=np.append(y_test_pred_n,X_test_pred)\n",
    "        y_test_real_n=np.append(y_test_real_n,y_test_n[j])\n",
    "\n",
    "        if d<down_level:\n",
    "            an_in=np.append(an_in,1)\n",
    "        elif d>up_level:\n",
    "            an_in=np.append(an_in,-1)\n",
    "        else:\n",
    "            an_in=np.append(an_in,0)\n",
    "\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print('Different distributions')\n",
    "\n",
    "        p_val=np.append(p_val,p)\n",
    "        X_test_train_batch=X_test[i*191:(i+1)*191][0:j]\n",
    "        y_test_train_batch=y_test[i*191:(i+1)*191][0:j]\n",
    "\n",
    "\n",
    "        ver_d=norm.cdf(d, loc=mean, scale=var)\n",
    "        print ('mean',mean, 'var',var, abs(ver_d))\n",
    "\n",
    "\n",
    "        eh=var_ep[int(8*abs((mean-ver_d)))]\n",
    "        \n",
    "        print (eh)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "          \n",
    "        #train on batch\n",
    "        model1.compile(\n",
    "                            optimizer=keras.optimizers.RMSprop(\n",
    "                            learning_rate=c,momentum=0.35),\n",
    "                            loss='mae',\n",
    "                            metrics=['mae'])\n",
    "\n",
    "        history=model1.fit(X_test_train_batch,y_test_train_batch,\n",
    "                            batch_size=32,\n",
    "                            verbose=1,\n",
    "                            epochs=int(eh),\n",
    "                            callbacks=[es,n,rp,sal])\n",
    "      \n",
    "        X_test_pred= model1.predict(np.expand_dims(X_test_n[j],axis=0))\n",
    "\n",
    "\n",
    "        d=y_test_n[j]-X_test_pred\n",
    "        diff_test_n=np.append(diff_test_n,d)\n",
    "        diff=diff_test_n\n",
    "\n",
    "        y_test_pred_n=np.append(y_test_pred_n,X_test_pred)\n",
    "        y_test_real_n=np.append(y_test_real_n,y_test_n[j])\n",
    "\n",
    "        mean=stats.describe(diff_test_n)[2]\n",
    "        var=stats.describe(diff_test_n)[3]\n",
    "        up_level=mean+3*var\n",
    "        down_level=mean-3*var\n",
    "\n",
    "\n",
    "        if d<down_level:\n",
    "            an_in=np.append(an_in,1)\n",
    "        elif d>up_level:\n",
    "            an_in=np.append(an_in,-1)\n",
    "        else:\n",
    "            an_in=np.append(an_in,0)\n",
    "\n",
    "\n",
    "\n",
    "    print (len(y_test_pred_n),len(y_test_real_n),len(an_in),len(p_val))      \n",
    "    df = pd.DataFrame({\"pred\" : y_test_pred_n, \"real\" : y_test_real_n, \"an_diff_in\" : an_in, \"p_val\" : p_val})\n",
    "    df.to_csv(\"/content/drive/MyDrive/checkpoint2/train_on_batch_foofoofoo_2_max_error.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f74e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"pred\" : y_test_pred_n, \"real\" : y_test_real_n, \"an_diff_in\" : an_in, \"p_val\" : p_val})\n",
    "df.to_csv(\"/content/drive/MyDrive/checkpoint2/train_on_batch_foofoofoo_2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
