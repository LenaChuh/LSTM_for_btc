{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_on_batch_lstm_eth_15min_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LenaChuh/LSTM_for_btc/blob/main/train_on_batch_lstm_eth_15min_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qcl4gAlNtb5",
        "outputId": "e0c31a5b-108d-446f-97ad-9fa294e5de79"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Aug 17 19:11:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_A27v2zN6so",
        "outputId": "70a2b61f-709e-4d1d-db50-9da8eb60a47b"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-CYZMD96XYZ",
        "outputId": "e236a388-68a4-465a-a89e-24bf051403a6"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20 kB 33.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 30 kB 38.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 40 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 51 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 61 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 71 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 81 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 92 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 96 kB 4.6 MB/s \n",
            "\u001b[?25h  Building wheel for kt-legacy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "aLP4L5LU7IWs",
        "outputId": "29783550-5469-44d1-f390-8039ef61b136"
      },
      "source": [
        "import keras_tuner as kt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1d9137e83faf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tuner\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_tuner'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj6kc-n55xNu"
      },
      "source": [
        "import csv\n",
        "import random\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import seaborn as sns\n",
        "from keras.layers import Input,Conv2D,LSTM\n",
        "from keras.layers import Reshape\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "from os import getcwd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#import keras_tuner\n",
        "import tensorflow as tf\n",
        "\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "\n",
        "from scipy import stats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSw08Xnm5xOU"
      },
      "source": [
        "def build_model_train(ak,bk,ck):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(191,1)))\n",
        "    for ix in range(0,ak):\n",
        "        model.add(tf.keras.layers.LSTM(units=bk,\n",
        "                            activation = 'tanh',\n",
        "                            recurrent_activation = 'sigmoid',\n",
        "                            return_sequences=True,\n",
        "                           recurrent_dropout = 0))\n",
        "\n",
        "    model.add(tf.keras.layers.LSTM(units=bk,  activation = 'tanh'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.RMSprop(\n",
        "        learning_rate=ck*2),\n",
        "        loss='mae',\n",
        "        metrics=['mae'])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp3ESfLu5xNv"
      },
      "source": [
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(191,1)))\n",
        "\n",
        "    for i in range(hp.Int('num_layers', 2, 6)):\n",
        "            model.add(\n",
        "                     tf.keras.layers.LSTM(units=hp.Int('units_',\n",
        "                                           128, 2048, 64),\n",
        "                                activation = 'tanh',\n",
        "                                recurrent_activation = 'sigmoid',\n",
        "                                return_sequences=True,\n",
        "                               recurrent_dropout = 0))\n",
        "    model.add(tf.keras.layers.LSTM(units=hp.Int('units_',128, 2048, 64),  activation = 'tanh'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "    \n",
        "    model.compile(\n",
        "            optimizer=keras.optimizers.RMSprop(\n",
        "                hp.Choice('learning_rate', [ 1e-3, 1e-4,1e-5,1e-6])),\n",
        "            loss='mae',\n",
        "            metrics=['mae'])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq_RGxwZ5xOB",
        "outputId": "84cf6e54-c662-4c75-ea8c-2e6cbd51db2c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjBn8paIrdJv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPa9-ib85xOA",
        "outputId": "f0faca5b-9f60-4ef8-e1f9-610aaf1782d7"
      },
      "source": [
        "def create_dataset(X, time_steps=1):\n",
        "    Xs = []\n",
        "    for i in range(time_steps,len(X) - time_steps):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        Xs.append(v)\n",
        "    return np.array(Xs)\n",
        "df=pd.read_csv('/content/drive/MyDrive/ETHUSDT15min.csv')\n",
        "len(df)\n",
        "df['index'] = np.arange(len(df))\n",
        "df['index']=df['index']+1\n",
        "train_size = len(df[:4*24*365+4*24*90*2])\n",
        "test_size = len(df) - train_size\n",
        "\n",
        "train, test = df.price_close.iloc[:train_size], df.price_close.iloc[train_size:len(df)]\n",
        "print(train.shape, test.shape)\n",
        "\n",
        "train=pd.DataFrame(train)\n",
        "test=pd.DataFrame(test)\n",
        "\n",
        "time_steps = 4*24*2\n",
        "\n",
        "X_train= create_dataset(train, time_steps)\n",
        "X_test= create_dataset(test,time_steps)\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "y_train = X_train[:,-1]\n",
        "X_train = X_train[:,:-1]\n",
        "\n",
        "y_test = X_test[:,-1]\n",
        "X_test = X_test[:,:-1]\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(52320,) (52539,)\n",
            "(51936, 192, 1)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(51936, 191, 1)"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWzbulI-5xOC"
      },
      "source": [
        "## Обновляем наш trainset +3 месяца"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rgLa3xf5xOD",
        "outputId": "c6e795e3-1716-48bc-979d-c65c431333a6"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(51936, 191, 1)"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E06DaztO5xOD",
        "outputId": "54927aa6-a6d1-4d7f-af15-de842eaecb7a"
      },
      "source": [
        "%%time\n",
        "\n",
        "from kerastuner import BayesianOptimization\n",
        "\n",
        "tuner_bo = kt.BayesianOptimization(\n",
        "            build_model,\n",
        "            objective='mae',\n",
        "            max_trials=6,\n",
        "            seed=42,\n",
        "            executions_per_trial=1,\n",
        "            overwrite=True\n",
        "        )\n",
        "tuner_bo.search(X_train, y_train,  epochs=1, validation_split=0.2, verbose=1)\n",
        "\n",
        "best_model = tuner_bo.get_best_models(num_models=1)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 6 Complete [00h 09m 53s]\n",
            "mae: 38.366519927978516\n",
            "\n",
            "Best mae So Far: 30.214330673217773\n",
            "Total elapsed time: 01h 05m 15s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "CPU times: user 48min 28s, sys: 1min 10s, total: 49min 38s\n",
            "Wall time: 1h 5min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckx4vR975xOD",
        "outputId": "eeec7406-7226-4aa5-9b75-2d68adb41d5f"
      },
      "source": [
        "tuner_bo.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='mae', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_: 2048\n",
            "learning_rate: 0.001\n",
            "Score: 30.214330673217773\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_: 576\n",
            "learning_rate: 0.001\n",
            "Score: 35.680477142333984\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 4\n",
            "units_: 1344\n",
            "learning_rate: 0.001\n",
            "Score: 38.366519927978516\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 6\n",
            "units_: 2048\n",
            "learning_rate: 0.001\n",
            "Score: 48.298255920410156\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_: 1856\n",
            "learning_rate: 1e-05\n",
            "Score: 155.6876678466797\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 5\n",
            "units_: 192\n",
            "learning_rate: 1e-06\n",
            "Score: 220.03173828125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5ZH6htW5xOE"
      },
      "source": [
        "hps = tuner_bo.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values \n",
        "a=hps['num_layers']\n",
        "b=hps['units_']\n",
        "c=hps['learning_rate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "hdjFYfmB5xOE",
        "outputId": "cb98125a-5224-475a-b246-842d77eae535"
      },
      "source": [
        "hps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-adba98fe6b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'hps' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIc5jwADKKz-"
      },
      "source": [
        "a=3\n",
        "b=2048\n",
        "c=6.250000073038109e-09/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmftTadd5xOE",
        "outputId": "79b293b8-3b27-4dfd-8c0b-b781ec06de77"
      },
      "source": [
        "\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model1=build_model_train(a,b,c)\n",
        "model1.load_weights('/content/drive/MyDrive/checkpoint2/2period_12-0.58.hdf5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 191, 2048)         16793600  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 191, 2048)         33562624  \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 191, 2048)         33562624  \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 2048)              33562624  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 117,483,521\n",
            "Trainable params: 117,483,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGhClDUX7HY6"
      },
      "source": [
        "\n",
        "es=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4,min_delta=0.0001, mode='min',restore_best_weights=True)\n",
        "n=tf.keras.callbacks.TerminateOnNaN()\n",
        "rp=tf.keras.callbacks.ReduceLROnPlateau(monitor='loss',mode='min', factor=0.3, patience=1, verbose=2, min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "checkpoint_filepath = '/content/drive/MyDrive/checkpoint7/retrain-{epoch:02d}-{loss:.2f}.hdf5'\n",
        "mcc = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhUG1gyB5xOF",
        "outputId": "d66675e6-897d-4a28-bb8b-976870d4b634"
      },
      "source": [
        "history = model1.fit(X_train,y_train,\n",
        "            batch_size=320,\n",
        "            verbose=2,\n",
        "            epochs=200,\n",
        "            callbacks=[es,n,rp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "218/218 - 878s - loss: 1.4131 - mae: 1.4131\n",
            "Epoch 2/200\n",
            "218/218 - 871s - loss: 1.4130 - mae: 1.4130\n",
            "Epoch 3/200\n",
            "218/218 - 871s - loss: 1.4129 - mae: 1.4129\n",
            "Epoch 4/200\n",
            "218/218 - 871s - loss: 1.4129 - mae: 1.4129\n",
            "Epoch 5/200\n",
            "218/218 - 871s - loss: 1.4129 - mae: 1.4129\n",
            "Epoch 6/200\n",
            "218/218 - 871s - loss: 1.4128 - mae: 1.4128\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 5.000000058430487e-08.\n",
            "Epoch 7/200\n",
            "218/218 - 871s - loss: 1.4126 - mae: 1.4126\n",
            "Epoch 8/200\n",
            "218/218 - 871s - loss: 1.4126 - mae: 1.4126\n",
            "Epoch 9/200\n",
            "218/218 - 871s - loss: 1.4126 - mae: 1.4126\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.5000000292152436e-08.\n",
            "Epoch 10/200\n",
            "218/218 - 871s - loss: 1.4124 - mae: 1.4124\n",
            "Epoch 11/200\n",
            "218/218 - 871s - loss: 1.4125 - mae: 1.4125\n",
            "Epoch 12/200\n",
            "218/218 - 871s - loss: 1.4124 - mae: 1.4124\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.2500000146076218e-08.\n",
            "Epoch 13/200\n",
            "218/218 - 871s - loss: 1.4124 - mae: 1.4124\n",
            "Epoch 14/200\n",
            "218/218 - 871s - loss: 1.4124 - mae: 1.4124\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.250000073038109e-09.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLIVJRgD5xOF"
      },
      "source": [
        "plt.plot(history.history['loss'],'b')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVJfDKXHxMHd"
      },
      "source": [
        "from tensorflow.keras.models import save_model, load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG7HhKy4L2vm"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/checkpoint2/diff_eth_2.csv\") as file_name:\n",
        "    diff = np.loadtxt(file_name, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBH83JaHdeNI",
        "outputId": "3d0fb852-9a9a-4a17-844b-0bd1fbe0cc05"
      },
      "source": [
        "diff"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1.79113525, -1.06578003,  1.83939697, ..., -0.17195648,\n",
              "       -0.24340393, -0.36013336])"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FY2W7zZx3xjW",
        "outputId": "397f6b7d-ee47-4026-87de-b1f66e21f394"
      },
      "source": [
        "diff_eth_train_percent=[]\n",
        "k=0\n",
        "for j in range(0,len(X_train)):\n",
        "    X_train_pred= model1.predict(np.expand_dims(X_train[j],axis=0))\n",
        "    print (k)\n",
        "    k+=1\n",
        "    dif=(X_train_pred-y_train[j])/y_train[j]\n",
        "    diff_eth_train_percent=np.append(diff_eth_train_percent,dif)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f100bde4c21a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX_train_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1774\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_pss_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmyaOlhs5_ov"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/checkpoint2/diff_eth_train_percent.csv\", diff_eth_train_percent, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrnHJT90wX4-"
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "\n",
        "class stopAtLossValue(Callback):\n",
        "\n",
        "        def on_batch_end(self, batch, logs={}):\n",
        "            THR = 0.6 #Assign THR with the value at which you want to stop training.\n",
        "            if logs.get('loss') <= THR:\n",
        "                 self.model.stop_training = True\n",
        "sal=stopAtLossValue()\n",
        "\n",
        "es=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4,min_delta=0.0001, mode='min',restore_best_weights=True)\n",
        "n=tf.keras.callbacks.TerminateOnNaN()\n",
        "rp=tf.keras.callbacks.ReduceLROnPlateau(monitor='loss',mode='min', factor=0.3, patience=1, verbose=2, min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne-bvmtmijlp"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/checkpoint2/diff_eth_train_percent.csv\") as file_name:\n",
        "    diff_eth_train_percent = np.loadtxt(file_name, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "csnHi8yWMGXb",
        "outputId": "e09de001-7905-40f1-cf7a-f33de95ff879"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/checkpoint2/diff_eth_2.csv\") as file_name:\n",
        "    diff = np.loadtxt(file_name, delimiter=\",\")\n",
        "    \n",
        "diff_test_n=diff\n",
        "import statistics\n",
        "from scipy.stats import norm\n",
        "eh=225\n",
        "var_ep=np.linspace(225, 225*2, num=10)\n",
        "\n",
        "mean=stats.describe(diff_test_n)[2]\n",
        "var=stats.describe(diff_test_n)[3]\n",
        "up_level=mean+3*var\n",
        "down_level=mean-3*var\n",
        "\n",
        "\n",
        "y_test_pred_n=[]\n",
        "y_test_real_n=[]\n",
        "an_n=[]\n",
        "an_in=[]\n",
        "p_val=[]\n",
        "k1=[]\n",
        "\n",
        "\n",
        "for i in range (0,int(len(X_test)/191.)):\n",
        "  print (i)\n",
        "\n",
        "  X_test_n=X_test[i*191:(i+1)*191]\n",
        "  y_test_n=y_test[i*191:(i+1)*191]\n",
        "  print (X_test_n.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for j in range(0,len(X_test_n)):\n",
        "    \n",
        "    \n",
        "    X_test_pred= model1.predict(np.expand_dims(X_test_n[j],axis=0))\n",
        "\n",
        " \n",
        "    d=y_test_n[j]-X_test_pred\n",
        "    diff_test_n=np.append(diff_test_n,d)\n",
        "    mean=stats.describe(diff_test_n)[2]\n",
        "    var=stats.describe(diff_test_n)[3]\n",
        "    up_level=mean+3*var\n",
        "    down_level=mean-3*var\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # compare samples\n",
        "    stat, p = ttest_ind(diff, diff_test_n)\n",
        "\n",
        "    alpha = 0.4\n",
        "\n",
        "    if p > alpha:\n",
        "        #print('Same distributions')\n",
        "        p_val=np.append(p_val,p)\n",
        "\n",
        "        y_test_pred_n=np.append(y_test_pred_n,X_test_pred)\n",
        "        y_test_real_n=np.append(y_test_real_n,y_test_n[j])\n",
        "\n",
        "        if d<down_level:\n",
        "          an_in=np.append(an_in,1)\n",
        "        elif d>up_level:\n",
        "          an_in=np.append(an_in,-1)\n",
        "        else:\n",
        "          an_in=np.append(an_in,0)\n",
        "\n",
        "        continue\n",
        "\n",
        "    else:\n",
        "        print('Different distributions')\n",
        "\n",
        "        p_val=np.append(p_val,p)\n",
        "        X_test_train_batch=X_test[i*191:(i+1)*191][0:j]\n",
        "        y_test_train_batch=y_test[i*191:(i+1)*191][0:j]\n",
        "\n",
        "\n",
        "        ver_d=norm.cdf(d, loc=mean, scale=var)\n",
        "        print ('mean',mean, 'var',var, abs(ver_d))\n",
        "\n",
        "\n",
        "        eh=var_ep[int(8*abs((mean-ver_d)))]\n",
        "      \n",
        "\n",
        "        print (eh)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "          \n",
        "        #train on batch\n",
        "        model1.compile(\n",
        "                            optimizer=keras.optimizers.RMSprop(\n",
        "                            learning_rate=c,momentum=0.35),\n",
        "                            loss='mae',\n",
        "                            metrics=['mae'])\n",
        "\n",
        "        history=model1.fit(X_test_train_batch,y_test_train_batch,\n",
        "                            batch_size=32,\n",
        "                            verbose=1,\n",
        "                            epochs=int(eh),\n",
        "                            callbacks=[es,n,rp,sal])\n",
        "      \n",
        "        X_test_pred= model1.predict(np.expand_dims(X_test_n[j],axis=0))\n",
        "\n",
        "\n",
        "        d=y_test_n[j]-X_test_pred\n",
        "        diff_test_n=np.append(diff_test_n,d)\n",
        "        diff=diff_test_n\n",
        "\n",
        "        y_test_pred_n=np.append(y_test_pred_n,X_test_pred)\n",
        "        y_test_real_n=np.append(y_test_real_n,y_test_n[j])\n",
        "\n",
        "        mean=stats.describe(diff_test_n)[2]\n",
        "        var=stats.describe(diff_test_n)[3]\n",
        "        up_level=mean+3*var\n",
        "        down_level=mean-3*var\n",
        "\n",
        "\n",
        "        if d<down_level:\n",
        "          an_in=np.append(an_in,1)\n",
        "        elif d>up_level:\n",
        "          an_in=np.append(an_in,-1)\n",
        "        else:\n",
        "          an_in=np.append(an_in,0)\n",
        "\n",
        "\n",
        "\n",
        "  print (len(y_test_pred_n),len(y_test_real_n),len(an_in),len(p_val))      \n",
        "  df = pd.DataFrame({\"pred\" : y_test_pred_n, \"real\" : y_test_real_n, \"an_diff_in\" : an_in, \"p_val\" : p_val})\n",
        "  df.to_csv(\"/content/drive/MyDrive/checkpoint2/train_on_batch_foofoofoo_2_max_error.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "(191, 191, 1)\n",
            "191 191 191 191\n",
            "1\n",
            "(191, 191, 1)\n",
            "382 382 382 382\n",
            "2\n",
            "(191, 191, 1)\n",
            "573 573 573 573\n",
            "3\n",
            "(191, 191, 1)\n",
            "764 764 764 764\n",
            "4\n",
            "(191, 191, 1)\n",
            "955 955 955 955\n",
            "5\n",
            "(191, 191, 1)\n",
            "Different distributions\n",
            "mean -0.17850878647990254 var 0.9526177834654173 [[0.78646853]]\n",
            "400.0\n",
            "Epoch 1/400\n",
            "5/5 [==============================] - 5s 381us/step - loss: 0.4716 - mae: 0.4716\n",
            "1146 1146 1146 1146\n",
            "6\n",
            "(191, 191, 1)\n",
            "1337 1337 1337 1337\n",
            "7\n",
            "(191, 191, 1)\n",
            "1528 1528 1528 1528\n",
            "8\n",
            "(191, 191, 1)\n",
            "1719 1719 1719 1719\n",
            "9\n",
            "(191, 191, 1)\n",
            "1910 1910 1910 1910\n",
            "10\n",
            "(191, 191, 1)\n",
            "2101 2101 2101 2101\n",
            "11\n",
            "(191, 191, 1)\n",
            "2292 2292 2292 2292\n",
            "12\n",
            "(191, 191, 1)\n",
            "2483 2483 2483 2483\n",
            "13\n",
            "(191, 191, 1)\n",
            "2674 2674 2674 2674\n",
            "14\n",
            "(191, 191, 1)\n",
            "2865 2865 2865 2865\n",
            "15\n",
            "(191, 191, 1)\n",
            "3056 3056 3056 3056\n",
            "16\n",
            "(191, 191, 1)\n",
            "3247 3247 3247 3247\n",
            "17\n",
            "(191, 191, 1)\n",
            "3438 3438 3438 3438\n",
            "18\n",
            "(191, 191, 1)\n",
            "3629 3629 3629 3629\n",
            "19\n",
            "(191, 191, 1)\n",
            "3820 3820 3820 3820\n",
            "20\n",
            "(191, 191, 1)\n",
            "4011 4011 4011 4011\n",
            "21\n",
            "(191, 191, 1)\n",
            "4202 4202 4202 4202\n",
            "22\n",
            "(191, 191, 1)\n",
            "4393 4393 4393 4393\n",
            "23\n",
            "(191, 191, 1)\n",
            "4584 4584 4584 4584\n",
            "24\n",
            "(191, 191, 1)\n",
            "4775 4775 4775 4775\n",
            "25\n",
            "(191, 191, 1)\n",
            "4966 4966 4966 4966\n",
            "26\n",
            "(191, 191, 1)\n",
            "Different distributions\n",
            "mean -0.17352413722313173 var 0.9346695167479719 [[0.99990853]]\n",
            "450.0\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7622 - mae: 1.7622\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7644 - mae: 1.7644WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2490s vs `on_train_batch_end` time: 0.4669s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7619 - mae: 1.7619\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7618 - mae: 1.7618\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7616 - mae: 1.7616\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7615 - mae: 1.7615\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7614 - mae: 1.7614\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7613 - mae: 1.7613\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7612 - mae: 1.7612\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7610 - mae: 1.7610\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7609 - mae: 1.7609\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7608 - mae: 1.7608\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7607 - mae: 1.7607\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7606 - mae: 1.7606\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7606 - mae: 1.7606\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7606 - mae: 1.7606\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 16/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7606 - mae: 1.7606\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 17/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7606 - mae: 1.7606\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "5157 5157 5157 5157\n",
            "27\n",
            "(191, 191, 1)\n",
            "5348 5348 5348 5348\n",
            "28\n",
            "(191, 191, 1)\n",
            "5539 5539 5539 5539\n",
            "29\n",
            "(191, 191, 1)\n",
            "5730 5730 5730 5730\n",
            "30\n",
            "(191, 191, 1)\n",
            "5921 5921 5921 5921\n",
            "31\n",
            "(191, 191, 1)\n",
            "6112 6112 6112 6112\n",
            "32\n",
            "(191, 191, 1)\n",
            "6303 6303 6303 6303\n",
            "33\n",
            "(191, 191, 1)\n",
            "6494 6494 6494 6494\n",
            "34\n",
            "(191, 191, 1)\n",
            "6685 6685 6685 6685\n",
            "35\n",
            "(191, 191, 1)\n",
            "6876 6876 6876 6876\n",
            "36\n",
            "(191, 191, 1)\n",
            "7067 7067 7067 7067\n",
            "37\n",
            "(191, 191, 1)\n",
            "7258 7258 7258 7258\n",
            "38\n",
            "(191, 191, 1)\n",
            "7449 7449 7449 7449\n",
            "39\n",
            "(191, 191, 1)\n",
            "7640 7640 7640 7640\n",
            "40\n",
            "(191, 191, 1)\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 699ms/step - loss: 1.7605 - mae: 1.7605\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.8323 - mae: 1.8323WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2493s vs `on_train_batch_end` time: 0.4673s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 700ms/step - loss: 1.7603 - mae: 1.7603\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7601 - mae: 1.7601\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7600 - mae: 1.7600\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7599 - mae: 1.7599\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7598 - mae: 1.7598\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7597 - mae: 1.7597\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7595 - mae: 1.7595\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7594 - mae: 1.7594\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7593 - mae: 1.7593\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7593 - mae: 1.7593\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7593 - mae: 1.7593\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7593 - mae: 1.7593\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7593 - mae: 1.7593\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 699ms/step - loss: 1.7593 - mae: 1.7593\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.8403 - mae: 1.8403WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2501s vs `on_train_batch_end` time: 0.4672s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7591 - mae: 1.7591\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7589 - mae: 1.7589\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7588 - mae: 1.7588\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7587 - mae: 1.7587\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7586 - mae: 1.7586\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7584 - mae: 1.7584\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7583 - mae: 1.7583\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7582 - mae: 1.7582\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7581 - mae: 1.7581\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7580 - mae: 1.7580\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7579 - mae: 1.7579\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7578 - mae: 1.7578\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7577 - mae: 1.7577\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7576 - mae: 1.7576\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 16/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7576 - mae: 1.7576\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 17/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7576 - mae: 1.7576\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 18/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7576 - mae: 1.7576\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 699ms/step - loss: 1.7576 - mae: 1.7576\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6807 - mae: 1.6807WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2492s vs `on_train_batch_end` time: 0.4674s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7574 - mae: 1.7574\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7572 - mae: 1.7572\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7571 - mae: 1.7571\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7570 - mae: 1.7570\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7568 - mae: 1.7568\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7567 - mae: 1.7567\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7566 - mae: 1.7566\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7565 - mae: 1.7565\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7564 - mae: 1.7564\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7563 - mae: 1.7563\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7561 - mae: 1.7561\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7560 - mae: 1.7560\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7559 - mae: 1.7559\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7558 - mae: 1.7558\n",
            "Epoch 16/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7557 - mae: 1.7557\n",
            "Epoch 17/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7556 - mae: 1.7556\n",
            "Epoch 18/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7555 - mae: 1.7555\n",
            "Epoch 19/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7554 - mae: 1.7554\n",
            "Epoch 20/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7553 - mae: 1.7553\n",
            "Epoch 21/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7551 - mae: 1.7551\n",
            "Epoch 22/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7550 - mae: 1.7550\n",
            "Epoch 23/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7549 - mae: 1.7549\n",
            "Epoch 24/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7548 - mae: 1.7548\n",
            "Epoch 25/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7547 - mae: 1.7547\n",
            "Epoch 26/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7546 - mae: 1.7546\n",
            "Epoch 27/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7545 - mae: 1.7545\n",
            "Epoch 28/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7544 - mae: 1.7544\n",
            "Epoch 29/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7543 - mae: 1.7543\n",
            "Epoch 30/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7541 - mae: 1.7541\n",
            "Epoch 31/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7540 - mae: 1.7540\n",
            "Epoch 32/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7539 - mae: 1.7539\n",
            "Epoch 33/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7538 - mae: 1.7538\n",
            "Epoch 34/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7537 - mae: 1.7537\n",
            "Epoch 35/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7536 - mae: 1.7536\n",
            "Epoch 36/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7535 - mae: 1.7535\n",
            "Epoch 37/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7534 - mae: 1.7534\n",
            "Epoch 38/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7533 - mae: 1.7533\n",
            "Epoch 39/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7531 - mae: 1.7531\n",
            "Epoch 40/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7530 - mae: 1.7530\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 41/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7529 - mae: 1.7529\n",
            "Epoch 42/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7529 - mae: 1.7529\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 43/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7529 - mae: 1.7529\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 44/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7529 - mae: 1.7529\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 45/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7529 - mae: 1.7529\n",
            "\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7529 - mae: 1.7529\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6672 - mae: 1.6672WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2492s vs `on_train_batch_end` time: 0.4657s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7527 - mae: 1.7527\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7525 - mae: 1.7525\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7524 - mae: 1.7524\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7523 - mae: 1.7523\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7522 - mae: 1.7522\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7520 - mae: 1.7520\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7519 - mae: 1.7519\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7518 - mae: 1.7518\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7517 - mae: 1.7517\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7516 - mae: 1.7516\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7515 - mae: 1.7515\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7514 - mae: 1.7514\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7513 - mae: 1.7513\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7513 - mae: 1.7513\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 16/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7513 - mae: 1.7513\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 17/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7512 - mae: 1.7512\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 18/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7512 - mae: 1.7512\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 699ms/step - loss: 1.7513 - mae: 1.7513\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6368 - mae: 1.6368WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2502s vs `on_train_batch_end` time: 0.4670s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7510 - mae: 1.7510\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7509 - mae: 1.7509\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7508 - mae: 1.7508\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7506 - mae: 1.7506\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7505 - mae: 1.7505\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7504 - mae: 1.7504\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7504 - mae: 1.7504\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7504 - mae: 1.7504\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7504 - mae: 1.7504\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7504 - mae: 1.7504\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7504 - mae: 1.7504\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7623 - mae: 1.7623WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2489s vs `on_train_batch_end` time: 0.4666s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7502 - mae: 1.7502\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7500 - mae: 1.7500\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7499 - mae: 1.7499\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7497 - mae: 1.7497\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7496 - mae: 1.7496\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7495 - mae: 1.7495\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7494 - mae: 1.7494\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7492 - mae: 1.7492\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7491 - mae: 1.7491\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7490 - mae: 1.7490\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7489 - mae: 1.7489\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7488 - mae: 1.7488\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7487 - mae: 1.7487\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7486 - mae: 1.7486\n",
            "Epoch 16/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7484 - mae: 1.7484\n",
            "Epoch 17/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7483 - mae: 1.7483\n",
            "Epoch 18/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7482 - mae: 1.7482\n",
            "Epoch 19/450\n",
            "4/4 [==============================] - 3s 695ms/step - loss: 1.7481 - mae: 1.7481\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 20/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7480 - mae: 1.7480\n",
            "Epoch 21/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7480 - mae: 1.7480\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 22/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7480 - mae: 1.7480\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 23/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7480 - mae: 1.7480\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 24/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7480 - mae: 1.7480\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7480 - mae: 1.7480\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6912 - mae: 1.6912WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2490s vs `on_train_batch_end` time: 0.4667s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7478 - mae: 1.7478\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7476 - mae: 1.7476\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7475 - mae: 1.7475\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7473 - mae: 1.7473\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7472 - mae: 1.7472\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7471 - mae: 1.7471\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7470 - mae: 1.7470\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7469 - mae: 1.7469\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7468 - mae: 1.7468\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7467 - mae: 1.7467\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7466 - mae: 1.7466\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7465 - mae: 1.7465\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7464 - mae: 1.7464\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7462 - mae: 1.7462\n",
            "Epoch 16/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7461 - mae: 1.7461\n",
            "Epoch 17/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7460 - mae: 1.7460\n",
            "Epoch 18/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7459 - mae: 1.7459\n",
            "Epoch 19/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7458 - mae: 1.7458\n",
            "Epoch 20/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7456 - mae: 1.7456\n",
            "Epoch 21/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7455 - mae: 1.7455\n",
            "Epoch 22/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7454 - mae: 1.7454\n",
            "Epoch 23/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7453 - mae: 1.7453\n",
            "Epoch 24/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7452 - mae: 1.7452\n",
            "Epoch 25/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7451 - mae: 1.7451\n",
            "Epoch 26/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7450 - mae: 1.7450\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 27/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7449 - mae: 1.7449\n",
            "Epoch 28/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7449 - mae: 1.7449\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 29/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7448 - mae: 1.7448\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 30/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7448 - mae: 1.7448\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 31/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7448 - mae: 1.7448\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a4961ae60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7449 - mae: 1.7449\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.8138 - mae: 1.8138WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2491s vs `on_train_batch_end` time: 0.4675s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7447 - mae: 1.7447\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7445 - mae: 1.7445\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7443 - mae: 1.7443\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7442 - mae: 1.7442\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7441 - mae: 1.7441\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7440 - mae: 1.7440\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7439 - mae: 1.7439\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7438 - mae: 1.7438\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7437 - mae: 1.7437\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7437 - mae: 1.7437\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7437 - mae: 1.7437\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7437 - mae: 1.7437\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9a47270e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7437 - mae: 1.7437\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.8545 - mae: 1.8545WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2494s vs `on_train_batch_end` time: 0.4673s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7435 - mae: 1.7435\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7433 - mae: 1.7433\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7432 - mae: 1.7432\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7431 - mae: 1.7431\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7429 - mae: 1.7429\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7428 - mae: 1.7428\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7427 - mae: 1.7427\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7426 - mae: 1.7426\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7425 - mae: 1.7425\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7425 - mae: 1.7425\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7424 - mae: 1.7424\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7424 - mae: 1.7424\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7424 - mae: 1.7424\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7424 - mae: 1.7424\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7447 - mae: 1.7447WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2488s vs `on_train_batch_end` time: 0.4680s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7422 - mae: 1.7422\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7420 - mae: 1.7420\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7419 - mae: 1.7419\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7418 - mae: 1.7418\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7416 - mae: 1.7416\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7415 - mae: 1.7415\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7414 - mae: 1.7414\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7413 - mae: 1.7413\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7412 - mae: 1.7412\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7411 - mae: 1.7411\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7409 - mae: 1.7409\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7408 - mae: 1.7408\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7407 - mae: 1.7407\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7406 - mae: 1.7406\n",
            "Epoch 16/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7405 - mae: 1.7405\n",
            "Epoch 17/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7404 - mae: 1.7404\n",
            "Epoch 18/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7402 - mae: 1.7402\n",
            "Epoch 19/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7401 - mae: 1.7401\n",
            "Epoch 20/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7400 - mae: 1.7400\n",
            "Epoch 21/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7399 - mae: 1.7399\n",
            "Epoch 22/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7398 - mae: 1.7398\n",
            "Epoch 23/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7397 - mae: 1.7397\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 24/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7396 - mae: 1.7396\n",
            "Epoch 25/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7396 - mae: 1.7396\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 26/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7396 - mae: 1.7396\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 27/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7395 - mae: 1.7395\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 28/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7395 - mae: 1.7395\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 699ms/step - loss: 1.7395 - mae: 1.7395\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7180 - mae: 1.7180WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2498s vs `on_train_batch_end` time: 0.4689s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 701ms/step - loss: 1.7393 - mae: 1.7393\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7392 - mae: 1.7392\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 702ms/step - loss: 1.7390 - mae: 1.7390\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 701ms/step - loss: 1.7389 - mae: 1.7389\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7388 - mae: 1.7388\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7387 - mae: 1.7387\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7386 - mae: 1.7386\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 700ms/step - loss: 1.7385 - mae: 1.7385\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7383 - mae: 1.7383\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 700ms/step - loss: 1.7382 - mae: 1.7382\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7381 - mae: 1.7381\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7381 - mae: 1.7381\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7380 - mae: 1.7380\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7380 - mae: 1.7380\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 16/450\n",
            "4/4 [==============================] - 3s 700ms/step - loss: 1.7380 - mae: 1.7380\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 17/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7380 - mae: 1.7380\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7380 - mae: 1.7380\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7976 - mae: 1.7976WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2496s vs `on_train_batch_end` time: 0.4682s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 701ms/step - loss: 1.7377 - mae: 1.7377\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7375 - mae: 1.7375\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7374 - mae: 1.7374\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7373 - mae: 1.7373\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7372 - mae: 1.7372\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7371 - mae: 1.7371\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7369 - mae: 1.7369\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7368 - mae: 1.7368\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7367 - mae: 1.7367\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7366 - mae: 1.7366\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7366 - mae: 1.7366\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7366 - mae: 1.7366\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7366 - mae: 1.7366\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7366 - mae: 1.7366\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7366 - mae: 1.7366\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7474 - mae: 1.7474WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2494s vs `on_train_batch_end` time: 0.4684s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7363 - mae: 1.7363\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7361 - mae: 1.7361\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7360 - mae: 1.7360\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7359 - mae: 1.7359\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7358 - mae: 1.7358\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7356 - mae: 1.7356\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7355 - mae: 1.7355\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7354 - mae: 1.7354\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7353 - mae: 1.7353\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7352 - mae: 1.7352\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 700ms/step - loss: 1.7351 - mae: 1.7351\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7350 - mae: 1.7350\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7350 - mae: 1.7350\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7350 - mae: 1.7350\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 16/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7349 - mae: 1.7349\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 17/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7349 - mae: 1.7349\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7349 - mae: 1.7349\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6998 - mae: 1.6998WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2493s vs `on_train_batch_end` time: 0.4676s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7347 - mae: 1.7347\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7346 - mae: 1.7346\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7344 - mae: 1.7344\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7343 - mae: 1.7343\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7342 - mae: 1.7342\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7341 - mae: 1.7341\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7340 - mae: 1.7340\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7338 - mae: 1.7338\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7337 - mae: 1.7337\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7336 - mae: 1.7336\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7335 - mae: 1.7335\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7335 - mae: 1.7335\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7335 - mae: 1.7335\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7335 - mae: 1.7335\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 16/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7335 - mae: 1.7335\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7334 - mae: 1.7334\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7553 - mae: 1.7553WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2493s vs `on_train_batch_end` time: 0.4682s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7332 - mae: 1.7332\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7330 - mae: 1.7330\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7329 - mae: 1.7329\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7328 - mae: 1.7328\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7327 - mae: 1.7327\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7327 - mae: 1.7327\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7327 - mae: 1.7327\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7327 - mae: 1.7327\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7327 - mae: 1.7327\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7327 - mae: 1.7327\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7256 - mae: 1.7256WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2492s vs `on_train_batch_end` time: 0.4666s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7325 - mae: 1.7325\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7324 - mae: 1.7324\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7322 - mae: 1.7322\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7321 - mae: 1.7321\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7320 - mae: 1.7320\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7319 - mae: 1.7319\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7318 - mae: 1.7318\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7317 - mae: 1.7317\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7316 - mae: 1.7316\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7315 - mae: 1.7315\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7314 - mae: 1.7314\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7314 - mae: 1.7314\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7314 - mae: 1.7314\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 15/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7313 - mae: 1.7313\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 16/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7313 - mae: 1.7313\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 8s 698ms/step - loss: 1.7314 - mae: 1.7314\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.8278 - mae: 1.8278WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2487s vs `on_train_batch_end` time: 0.4678s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7312 - mae: 1.7312\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7310 - mae: 1.7310\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7309 - mae: 1.7309\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7308 - mae: 1.7308\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7307 - mae: 1.7307\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7306 - mae: 1.7306\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7305 - mae: 1.7305\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7305 - mae: 1.7305\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7305 - mae: 1.7305\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7305 - mae: 1.7305\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7305 - mae: 1.7305\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7305 - mae: 1.7305\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7311 - mae: 1.7311WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2484s vs `on_train_batch_end` time: 0.4669s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7303 - mae: 1.7303\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7301 - mae: 1.7301\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7300 - mae: 1.7300\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7299 - mae: 1.7299\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7298 - mae: 1.7298\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7297 - mae: 1.7297\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7296 - mae: 1.7296\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7296 - mae: 1.7296\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7296 - mae: 1.7296\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7296 - mae: 1.7296\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7296 - mae: 1.7296\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6279 - mae: 1.6279WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2493s vs `on_train_batch_end` time: 0.4665s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7294 - mae: 1.7294\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7293 - mae: 1.7293\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7292 - mae: 1.7292\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7291 - mae: 1.7291\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7290 - mae: 1.7290\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7290 - mae: 1.7290\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7289 - mae: 1.7289\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7289 - mae: 1.7289\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7289 - mae: 1.7289\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7289 - mae: 1.7289\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7097 - mae: 1.7097WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2487s vs `on_train_batch_end` time: 0.4675s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7287 - mae: 1.7287\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7286 - mae: 1.7286\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7284 - mae: 1.7284\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7283 - mae: 1.7283\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7282 - mae: 1.7282\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7281 - mae: 1.7281\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7280 - mae: 1.7280\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7279 - mae: 1.7279\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7278 - mae: 1.7278\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7278 - mae: 1.7278\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7278 - mae: 1.7278\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7278 - mae: 1.7278\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7278 - mae: 1.7278\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7278 - mae: 1.7278\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6616 - mae: 1.6616WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2490s vs `on_train_batch_end` time: 0.4676s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7275 - mae: 1.7275\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7274 - mae: 1.7274\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7273 - mae: 1.7273\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7272 - mae: 1.7272\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7271 - mae: 1.7271\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7270 - mae: 1.7270\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7269 - mae: 1.7269\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7269 - mae: 1.7269\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7269 - mae: 1.7269\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7269 - mae: 1.7269\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 8s 699ms/step - loss: 1.7269 - mae: 1.7269\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7060 - mae: 1.7060WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2498s vs `on_train_batch_end` time: 0.4669s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7267 - mae: 1.7267\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7266 - mae: 1.7266\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7265 - mae: 1.7265\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7264 - mae: 1.7264\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7263 - mae: 1.7263\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7261 - mae: 1.7261\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7260 - mae: 1.7260\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7259 - mae: 1.7259\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7258 - mae: 1.7258\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7258 - mae: 1.7258\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7258 - mae: 1.7258\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7258 - mae: 1.7258\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7258 - mae: 1.7258\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7258 - mae: 1.7258\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6462 - mae: 1.6462WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2490s vs `on_train_batch_end` time: 0.4679s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7255 - mae: 1.7255\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7254 - mae: 1.7254\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7253 - mae: 1.7253\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7251 - mae: 1.7251\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7250 - mae: 1.7250\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7249 - mae: 1.7249\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7248 - mae: 1.7248\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7247 - mae: 1.7247\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7247 - mae: 1.7247\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7247 - mae: 1.7247\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7247 - mae: 1.7247\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7247 - mae: 1.7247\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7246 - mae: 1.7246\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6814 - mae: 1.6814WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2491s vs `on_train_batch_end` time: 0.4670s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7244 - mae: 1.7244\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7243 - mae: 1.7243\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7242 - mae: 1.7242\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7241 - mae: 1.7241\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7240 - mae: 1.7240\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7239 - mae: 1.7239\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7238 - mae: 1.7238\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7238 - mae: 1.7238\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7238 - mae: 1.7238\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7238 - mae: 1.7238\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7238 - mae: 1.7238\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6638 - mae: 1.6638WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2489s vs `on_train_batch_end` time: 0.4675s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7236 - mae: 1.7236\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7235 - mae: 1.7235\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7234 - mae: 1.7234\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7233 - mae: 1.7233\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 700ms/step - loss: 1.7231 - mae: 1.7231\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7230 - mae: 1.7230\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7229 - mae: 1.7229\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7228 - mae: 1.7228\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7228 - mae: 1.7228\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7228 - mae: 1.7228\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7228 - mae: 1.7228\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7228 - mae: 1.7228\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7228 - mae: 1.7228\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7358 - mae: 1.7358WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2486s vs `on_train_batch_end` time: 0.4670s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7226 - mae: 1.7226\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7224 - mae: 1.7224\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7223 - mae: 1.7223\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7222 - mae: 1.7222\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7221 - mae: 1.7221\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7220 - mae: 1.7220\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7220 - mae: 1.7220\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7219 - mae: 1.7219\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7219 - mae: 1.7219\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7219 - mae: 1.7219\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7219 - mae: 1.7219\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6404 - mae: 1.6404WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2489s vs `on_train_batch_end` time: 0.4659s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7218 - mae: 1.7218\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7216 - mae: 1.7216\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7215 - mae: 1.7215\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7214 - mae: 1.7214\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7213 - mae: 1.7213\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7212 - mae: 1.7212\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7211 - mae: 1.7211\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7211 - mae: 1.7211\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7211 - mae: 1.7211\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7210 - mae: 1.7210\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7210 - mae: 1.7210\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 8s 696ms/step - loss: 1.7210 - mae: 1.7210\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7237 - mae: 1.7237WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2487s vs `on_train_batch_end` time: 0.4665s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7208 - mae: 1.7208\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7206 - mae: 1.7206\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7205 - mae: 1.7205\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7204 - mae: 1.7204\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7203 - mae: 1.7203\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7202 - mae: 1.7202\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7201 - mae: 1.7201\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7200 - mae: 1.7200\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7199 - mae: 1.7199\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7198 - mae: 1.7198\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7198 - mae: 1.7198\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 13/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7198 - mae: 1.7198\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 14/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7198 - mae: 1.7198\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7199 - mae: 1.7199\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7056 - mae: 1.7056WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2490s vs `on_train_batch_end` time: 0.4663s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7197 - mae: 1.7197\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7195 - mae: 1.7195\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7194 - mae: 1.7194\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7193 - mae: 1.7193\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7192 - mae: 1.7192\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 695ms/step - loss: 1.7191 - mae: 1.7191\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7191 - mae: 1.7191\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7191 - mae: 1.7191\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7191 - mae: 1.7191\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7191 - mae: 1.7191\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7191 - mae: 1.7191\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.8039 - mae: 1.8039WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2490s vs `on_train_batch_end` time: 0.4673s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7189 - mae: 1.7189\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7187 - mae: 1.7187\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7186 - mae: 1.7186\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7185 - mae: 1.7185\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7185 - mae: 1.7185\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7185 - mae: 1.7185\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7185 - mae: 1.7185\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7185 - mae: 1.7185\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7185 - mae: 1.7185\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7535 - mae: 1.7535WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2488s vs `on_train_batch_end` time: 0.4674s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7183 - mae: 1.7183\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7182 - mae: 1.7182\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7181 - mae: 1.7181\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7180 - mae: 1.7180\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7179 - mae: 1.7179\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7178 - mae: 1.7178\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7178 - mae: 1.7178\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 696ms/step - loss: 1.7177 - mae: 1.7177\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7177 - mae: 1.7177\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7177 - mae: 1.7177\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 697ms/step - loss: 1.7177 - mae: 1.7177\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6362 - mae: 1.6362WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2491s vs `on_train_batch_end` time: 0.4666s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7175 - mae: 1.7175\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7174 - mae: 1.7174\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7172 - mae: 1.7172\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7171 - mae: 1.7171\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7170 - mae: 1.7170\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7170 - mae: 1.7170\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7170 - mae: 1.7170\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7170 - mae: 1.7170\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7170 - mae: 1.7170\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 698ms/step - loss: 1.7170 - mae: 1.7170\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7889 - mae: 1.7889WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2493s vs `on_train_batch_end` time: 0.4669s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7168 - mae: 1.7168\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7166 - mae: 1.7166\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7165 - mae: 1.7165\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7164 - mae: 1.7164\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7163 - mae: 1.7163\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7162 - mae: 1.7162\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7162 - mae: 1.7162\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7162 - mae: 1.7162\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7161 - mae: 1.7161\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7161 - mae: 1.7161\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 699ms/step - loss: 1.7161 - mae: 1.7161\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.6373 - mae: 1.6373WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2489s vs `on_train_batch_end` time: 0.4679s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7159 - mae: 1.7159\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7158 - mae: 1.7158\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7157 - mae: 1.7157\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7156 - mae: 1.7156\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7155 - mae: 1.7155\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7155 - mae: 1.7155\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7155 - mae: 1.7155\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7155 - mae: 1.7155\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7155 - mae: 1.7155\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 7s 699ms/step - loss: 1.7154 - mae: 1.7154\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.5181 - mae: 1.5181WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2492s vs `on_train_batch_end` time: 0.4672s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7152 - mae: 1.7152\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 697ms/step - loss: 1.7151 - mae: 1.7151\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7150 - mae: 1.7150\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7148 - mae: 1.7148\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7147 - mae: 1.7147\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7146 - mae: 1.7146\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7145 - mae: 1.7145\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7145 - mae: 1.7145\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7145 - mae: 1.7145\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7145 - mae: 1.7145\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7145 - mae: 1.7145\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "слишком большая ошибка\n",
            "Epoch 1/450\n",
            "4/4 [==============================] - 8s 698ms/step - loss: 1.7145 - mae: 1.7145\n",
            "Epoch 2/450\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 1.7994 - mae: 1.7994WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2486s vs `on_train_batch_end` time: 0.4681s). Check your callbacks.\n",
            "4/4 [==============================] - 3s 700ms/step - loss: 1.7143 - mae: 1.7143\n",
            "Epoch 3/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7142 - mae: 1.7142\n",
            "Epoch 4/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7141 - mae: 1.7141\n",
            "Epoch 5/450\n",
            "4/4 [==============================] - 3s 700ms/step - loss: 1.7140 - mae: 1.7140\n",
            "Epoch 6/450\n",
            "4/4 [==============================] - 3s 700ms/step - loss: 1.7139 - mae: 1.7139\n",
            "Epoch 7/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7138 - mae: 1.7138\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.375000109557164e-10.\n",
            "Epoch 8/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7137 - mae: 1.7137\n",
            "Epoch 9/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7136 - mae: 1.7136\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.8124998996403857e-10.\n",
            "Epoch 10/450\n",
            "4/4 [==============================] - 3s 699ms/step - loss: 1.7136 - mae: 1.7136\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.437499865454611e-11.\n",
            "Epoch 11/450\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 1.7136 - mae: 1.7136\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.5312500012697468e-11.\n",
            "Epoch 12/450\n",
            "4/4 [==============================] - 3s 700ms/step - loss: 1.7136 - mae: 1.7136\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 7.593750107892649e-12.\n",
            "7867 7867 7867 7831\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3153f9822bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_pred_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_real_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0man_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"pred\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0my_test_pred_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"real\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0my_test_real_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"an_diff_in\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0man_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"p_val\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mp_val\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/checkpoint2/train_on_batch_foofoofoo_2_max_error.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "2ipqlsz74SJj",
        "outputId": "0128db0f-2d1a-4528-a619-5d5c9fa459b1"
      },
      "source": [
        "df = pd.DataFrame({\"pred\" : y_test_pred_n, \"real\" : y_test_real_n, \"an_diff_in\" : an_in, \"p_val\" : p_val})\n",
        "df.to_csv(\"/content/drive/MyDrive/checkpoint2/train_on_batch_foofoofoo_2.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-051d5bfa4830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"pred\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0my_test_pred_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"real\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0my_test_real_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"an_diff_in\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0man_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"p_val\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mp_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7823\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/checkpoint2/train_on_batch_foofoofoo_2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "aXCWbotbDoan",
        "outputId": "812ace55-6818-4b16-c3ef-0e02844b86d8"
      },
      "source": [
        "\n",
        "len(p_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2aeddcec45fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'p_val' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVERTfaTD0t1"
      },
      "source": [
        "len(an_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOyTezjAD2xx"
      },
      "source": [
        "len(y_test_real_n) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "n1LPdHK8D4cd",
        "outputId": "7f7053cb-c604-47ec-fa23-d25b9a91de96"
      },
      "source": [
        "len(y_test_pred_n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c8a498d2f4ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_pred_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test_pred_n' is not defined"
          ]
        }
      ]
    }
  ]
}